{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe17a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import datetime as dt\n",
    "import random\n",
    "import os \n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, GRU,LSTM, Dense,Lambda,Conv1D\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "PATIENCE = 20\n",
    "MAX_EPOCH = 100\n",
    "TRAIN_STEPS = 1 * 168\n",
    "PREDICT_STEPS = 24\n",
    "WINDOW_SIZE = TRAIN_STEPS + PREDICT_STEPS \n",
    "\n",
    "LSTM_DIM = 128\n",
    "INPUT_FEATURES = 10\n",
    "OUTPUT_FEATURES = 1\n",
    "filters = 16\n",
    "krnl_sz = 2\n",
    "DECOD_DENSE = 24\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e5d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = 'C:\\\\Users\\\\Zain Ahmed\\\\Desktop\\\\Literature review\\\\Project Folder\\\\Data.xlsx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb35c9f",
   "metadata": {},
   "source": [
    "# Loading the data from execl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d8867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(FILE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354109b",
   "metadata": {},
   "source": [
    "# Keeping DATE,Time and Load Columns Only \n",
    "# Also keeping daily hours between 0-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cdbd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time']=data['Time'].astype(int)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad82b7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dayodweek', 'workday dinary', 'workday', 'Weekday', 'DATE', 'Time',\n",
       "       ' Load(KW)   ', ' KVAR  ', 'KVA', 'P/F', 'pload', 'pkvar', 'pkva',\n",
       "       'ppf', 'Temp (°C)', 'Dew Point Temp (°C)', 'Rel Hum (%)',\n",
       "       'Wind Dir (10s deg)', 'Wind Spd (km/h)', 'Visibility (km)',\n",
       "       'Stn Press (kPa)', 'Wind Chill'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ad8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.loc[:,('DATE','Time',' Load(KW)   ')]\n",
    "#DROPPING WIND CHILL DUE TO HIGH NANs\n",
    "data = data.loc[:,('DATE','Time',' Load(KW)   ','Temp (°C)','Dew Point Temp (°C)','Rel Hum (%)','Wind Dir (10s deg)','Wind Spd (km/h)','Visibility (km)','Stn Press (kPa)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764631f9",
   "metadata": {},
   "source": [
    "# Concatenate Date and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "746ef898",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['datetime'] = data['DATE'].astype('str') + '-' + data['Time'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c8869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['datetime']=pd.to_datetime(data['datetime'],format='%Y-%m-%d-%H')\n",
    "data['is_weekday'] = (data['datetime'].dt.weekday<=5).astype('int')\n",
    "data['month'] = (data['datetime']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf857e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4903309",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['DATE','Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fb057a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Load(KW)   ', 'Temp (°C)', 'Dew Point Temp (°C)', 'Rel Hum (%)',\n",
       "       'Wind Dir (10s deg)', 'Wind Spd (km/h)', 'Visibility (km)',\n",
       "       'Stn Press (kPa)', 'is_weekday', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8e982",
   "metadata": {},
   "source": [
    "# We will ensure the continuity of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb73c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of breaks in the data are 3 which is 0.0081 percent of the total data\n"
     ]
    }
   ],
   "source": [
    "num_of_bre = (data.asfreq(freq='1H').shape[0]) - (data.shape[0])\n",
    "percen = ((num_of_bre)/data.shape[0])*100\n",
    "print('The number of breaks in the data are {} which is {:0.2} percent of the total data'.format(num_of_bre,percen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6de35",
   "metadata": {},
   "source": [
    "# Make the data continous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b250c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load(KW)</th>\n",
       "      <th>Temp (°C)</th>\n",
       "      <th>Dew Point Temp (°C)</th>\n",
       "      <th>Rel Hum (%)</th>\n",
       "      <th>Wind Dir (10s deg)</th>\n",
       "      <th>Wind Spd (km/h)</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Stn Press (kPa)</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-02 00:00:00</th>\n",
       "      <td>10809</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>98.09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 01:00:00</th>\n",
       "      <td>10890</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>80.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>98.09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 02:00:00</th>\n",
       "      <td>10803</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>98.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 03:00:00</th>\n",
       "      <td>10839</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>98.13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02 04:00:00</th>\n",
       "      <td>10812</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>98.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Load(KW)     Temp (°C)  Dew Point Temp (°C)  \\\n",
       "datetime                                                            \n",
       "2016-01-02 00:00:00         10809       -3.7                 -6.5   \n",
       "2016-01-02 01:00:00         10890       -3.9                 -6.9   \n",
       "2016-01-02 02:00:00         10803       -4.1                 -7.2   \n",
       "2016-01-02 03:00:00         10839       -4.0                 -7.1   \n",
       "2016-01-02 04:00:00         10812       -4.3                 -7.3   \n",
       "\n",
       "                     Rel Hum (%)  Wind Dir (10s deg)  Wind Spd (km/h)  \\\n",
       "datetime                                                                \n",
       "2016-01-02 00:00:00         81.0                29.0             30.0   \n",
       "2016-01-02 01:00:00         80.0                28.0             32.0   \n",
       "2016-01-02 02:00:00         79.0                29.0             27.0   \n",
       "2016-01-02 03:00:00         79.0                28.0             34.0   \n",
       "2016-01-02 04:00:00         80.0                29.0             25.0   \n",
       "\n",
       "                     Visibility (km)  Stn Press (kPa)  is_weekday  month  \n",
       "datetime                                                                  \n",
       "2016-01-02 00:00:00             24.1            98.09           1      1  \n",
       "2016-01-02 01:00:00             24.1            98.09           1      1  \n",
       "2016-01-02 02:00:00             24.1            98.15           1      1  \n",
       "2016-01-02 03:00:00             24.1            98.13           1      1  \n",
       "2016-01-02 04:00:00             24.1            98.16           1      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8667cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.asfreq(freq='1H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f60a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='datetime'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(y=' Load(KW)   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e79530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37224, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165aaf7",
   "metadata": {},
   "source": [
    "# Dividing our data in train, validation and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ec559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_id = int((data.shape[0]*0.75)/24)*24\n",
    "val_id = int((data.shape[0]*0.90)/24)*24\n",
    "tra_data = data.iloc[:tr_id,:]\n",
    "val_data = data.iloc[tr_id:val_id,:]\n",
    "tes_data = data.iloc[val_id:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba52d7",
   "metadata": {},
   "source": [
    "# Now we will write the proprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25a06c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(sample):\n",
    "    '''\n",
    "    Takes a dataframe and \n",
    "            \n",
    "    - replaces NA values by forward filling\n",
    "    \n",
    "    '''\n",
    "    ## Use the below line of code to sample data based on hours \n",
    "    ##sample = sample[(sample.index.dayofweek<5) & ((of_da_fi.index.hour>4) & (of_da_fi.index.hour<19))]\n",
    "    \n",
    "    #using forward filling method to fill the missing data \n",
    "        \n",
    "    sample = sample.fillna(method='ffill')\n",
    "    \n",
    "    ## This line of code checks for NA values \n",
    "    \n",
    "    check_na = int(sample.isnull().sum().sum())\n",
    "    \n",
    "    print('There are {} NA values in the dataframe'.format(check_na))\n",
    "    \n",
    "    #plt.figure(figsize=(3,3))\n",
    "    \n",
    "    #sns.violinplot(data=sample)\n",
    "    \n",
    "    #plt.xticks(rotation=90)\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5ac0169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 NA values in the dataframe\n"
     ]
    }
   ],
   "source": [
    "train_data = pre_process(tra_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "234a624c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 NA values in the dataframe\n"
     ]
    }
   ],
   "source": [
    "vali_data = pre_process(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fbeb1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 NA values in the dataframe\n"
     ]
    }
   ],
   "source": [
    "test_data = pre_process(tes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c7fb4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Load(KW)              0\n",
       "Temp (°C)              0\n",
       "Dew Point Temp (°C)    0\n",
       "Rel Hum (%)            0\n",
       "Wind Dir (10s deg)     0\n",
       "Wind Spd (km/h)        0\n",
       "Visibility (km)        0\n",
       "Stn Press (kPa)        0\n",
       "is_weekday             0\n",
       "month                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes_data.fillna(method='ffill').isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eb124d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3744, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53925d",
   "metadata": {},
   "source": [
    "# Rolling window function for 1D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfa201b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(array_data,input_size,output_size,offset):\n",
    "    '''\n",
    "    The function takes a series array_data of size (size,) \n",
    "\n",
    "    and generates\n",
    "    \n",
    "    a array of size (input_size,((array_size-(input_size+output_size)/stride)+1)) as inputs \n",
    "    \n",
    "    and array of size (array_size-(input_size+output_size)/stride)+1)as output \n",
    "    \n",
    "    '''\n",
    "        \n",
    "    # Normalizing the dataset\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaler = scaler.fit(array_data)\n",
    "    \n",
    "    array_data = scaler.transform(array_data)\n",
    "    \n",
    "#     lab_data = array_data[:,0]\n",
    "    \n",
    "#     for i in range(input_size,len(array_data)-output_size+1,offset):\n",
    "            \n",
    "#             data.append(array_data[i-input_size:i,0:array_data.shape[1]])\n",
    "    \n",
    "#             labels.append(lab_data[i:i+output_size])\n",
    "\n",
    "        \n",
    "    data_idx = sliding_window_view(np.arange(array_data.shape[0]).reshape(-1),window_shape=input_size)[::offset][:-1]\n",
    "    \n",
    "    data = array_data[data_idx]\n",
    "\n",
    "    labels = sliding_window_view(array_data[input_size:,0].reshape(-1),window_shape=output_size)[::offset]\n",
    "    \n",
    "    input_decoder = np.zeros((data.shape[0],1,LSTM_DIM+OUTPUT_FEATURES))\n",
    "\n",
    "    \n",
    "    assert data.shape[0] == labels.shape[0],\"Training rows and labels are unequal\"    \n",
    "    \n",
    "#    if output_size == offset:\n",
    "        \n",
    "#        ra_in = random.randint(0,data.shape[0]-2) \n",
    "        \n",
    "#        a = data[ra_in+1,-offset:]\n",
    "        \n",
    "#        b = labels[ra_in]\n",
    "        \n",
    "#        np.alltrue(a == b)\n",
    "    \n",
    "#    data = np.expand_dims(data,axis=2)\n",
    "    \n",
    "#    labels = np.expand_dims(labels,axis=2)\n",
    "    \n",
    "#    data = np.array(data)\n",
    "    \n",
    "#    labels = np.array(labels)\n",
    "        \n",
    "    return data,labels,scaler,array_data,input_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "501e63f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load(KW)</th>\n",
       "      <th>Temp (°C)</th>\n",
       "      <th>Dew Point Temp (°C)</th>\n",
       "      <th>Rel Hum (%)</th>\n",
       "      <th>Wind Dir (10s deg)</th>\n",
       "      <th>Wind Spd (km/h)</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Stn Press (kPa)</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-28 00:00:00</th>\n",
       "      <td>10152.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>99.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28 01:00:00</th>\n",
       "      <td>10092.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>99.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28 02:00:00</th>\n",
       "      <td>9960.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>99.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28 03:00:00</th>\n",
       "      <td>10008.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>96.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>99.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28 04:00:00</th>\n",
       "      <td>10296.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>99.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 19:00:00</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>99.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 20:00:00</th>\n",
       "      <td>10332.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>99.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 21:00:00</th>\n",
       "      <td>9984.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 22:00:00</th>\n",
       "      <td>9744.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 23:00:00</th>\n",
       "      <td>9660.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3744 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Load(KW)     Temp (°C)  Dew Point Temp (°C)  \\\n",
       "datetime                                                            \n",
       "2019-10-28 00:00:00       10152.0        3.6                  2.5   \n",
       "2019-10-28 01:00:00       10092.0        3.7                  3.0   \n",
       "2019-10-28 02:00:00        9960.0        4.0                  3.5   \n",
       "2019-10-28 03:00:00       10008.0        3.4                  2.8   \n",
       "2019-10-28 04:00:00       10296.0        2.8                  2.2   \n",
       "...                           ...        ...                  ...   \n",
       "2020-03-31 19:00:00       10500.0        0.6                  0.4   \n",
       "2020-03-31 20:00:00       10332.0        1.6                  1.4   \n",
       "2020-03-31 21:00:00        9984.0        2.3                  2.1   \n",
       "2020-03-31 22:00:00        9744.0        2.6                  2.5   \n",
       "2020-03-31 23:00:00        9660.0        2.2                  2.1   \n",
       "\n",
       "                     Rel Hum (%)  Wind Dir (10s deg)  Wind Spd (km/h)  \\\n",
       "datetime                                                                \n",
       "2019-10-28 00:00:00         92.0                36.0             23.0   \n",
       "2019-10-28 01:00:00         95.0                36.0             18.0   \n",
       "2019-10-28 02:00:00         96.0                35.0             20.0   \n",
       "2019-10-28 03:00:00         96.0                36.0             30.0   \n",
       "2019-10-28 04:00:00         96.0                36.0             29.0   \n",
       "...                          ...                 ...              ...   \n",
       "2020-03-31 19:00:00         99.0                 9.0             10.0   \n",
       "2020-03-31 20:00:00         99.0                11.0             14.0   \n",
       "2020-03-31 21:00:00         99.0                14.0             17.0   \n",
       "2020-03-31 22:00:00         99.0                15.0             17.0   \n",
       "2020-03-31 23:00:00         99.0                14.0             18.0   \n",
       "\n",
       "                     Visibility (km)  Stn Press (kPa)  is_weekday  month  \n",
       "datetime                                                                  \n",
       "2019-10-28 00:00:00             24.1            99.83         1.0   10.0  \n",
       "2019-10-28 01:00:00             16.1            99.85         1.0   10.0  \n",
       "2019-10-28 02:00:00             16.1            99.88         1.0   10.0  \n",
       "2019-10-28 03:00:00              8.1            99.88         1.0   10.0  \n",
       "2019-10-28 04:00:00              8.1            99.92         1.0   10.0  \n",
       "...                              ...              ...         ...    ...  \n",
       "2020-03-31 19:00:00              0.6            99.93         1.0    3.0  \n",
       "2020-03-31 20:00:00              0.2            99.97         1.0    3.0  \n",
       "2020-03-31 21:00:00              0.2           100.00         1.0    3.0  \n",
       "2020-03-31 22:00:00              0.2           100.03         1.0    3.0  \n",
       "2020-03-31 23:00:00              0.2           100.05         1.0    3.0  \n",
       "\n",
       "[3744 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92814007",
   "metadata": {},
   "source": [
    "# Creating the rolling window for input size 168 and output window size of 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d0388c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_data_sli,tra_lab,tra_sca,tra_stan,tra_decod = rolling_window(train_data,input_size=TRAIN_STEPS,output_size=24,offset=24)\n",
    "val_data_sli,val_lab,val_sca,val_stan,val_decod = rolling_window(vali_data,input_size=TRAIN_STEPS,output_size=24,offset=24)\n",
    "tes_data_sli,tes_lab,test_scaler,tes_stan,tes_decod = rolling_window(test_data,input_size=TRAIN_STEPS,output_size=24,offset=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd6a2cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1156, 168, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra_data_sli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28e4d225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1156, 24)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra_lab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03cfa6",
   "metadata": {},
   "source": [
    "# We will now focus on Seq2Seq Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0832752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples are 1156\n",
      "Number of validation samples are 225\n",
      "Number of test samples are 149\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples are {}\".format(tra_data_sli.shape[0]))\n",
    "print(\"Number of validation samples are {}\".format(val_data_sli.shape[0]))\n",
    "print(\"Number of test samples are {}\".format(tes_data_sli.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e776a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1156, 24)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra_lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9454561c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1156, 168, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra_data_sli.shape\n",
    "#model_seq_to_seq_without_atten = keras.models.load_model('Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler_no_attention.h5') \n",
    "#predict_wout_attention = model_seq_to_seq_without_atten.predict(x=[tes_data_sli,tes_decod])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1dca157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, verbose=0):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        self.verbose= verbose\n",
    "\n",
    "    def call(self, query, values):\n",
    "        if self.verbose:\n",
    "            print('\\n******* Bahdanau Attention STARTS******')\n",
    "            print('query (decoder hidden state): (batch_size, hidden size) ', query.shape)\n",
    "            print('values (encoder all hidden state): (batch_size, max_len, hidden size) ', values.shape)\n",
    "\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('query_with_time_axis:(batch_size, 1, hidden size) ', query_with_time_axis.shape)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        if self.verbose:\n",
    "            print('score: (batch_size, max_length, 1) ',score.shape)\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        if self.verbose:\n",
    "            print('attention_weights: (batch_size, max_length, 1) ',attention_weights.shape)\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        if self.verbose:\n",
    "            print('context_vector before reduce_sum: (batch_size, max_length, hidden_size) ',context_vector.shape)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        if self.verbose:\n",
    "            print('context_vector after reduce_sum: (batch_size, hidden_size) ',context_vector.shape)\n",
    "            print('\\n******* Bahdanau Attention ENDS******')\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c95d33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# input_timesteps = 168\n",
    "# features = 8\n",
    "# output_timesteps = 24\n",
    "# lstm_dim = 256\n",
    "\n",
    "# def encoder_decoder_model(batch_size):\n",
    "\n",
    "#     encoder_inputs = Input(shape=(input_timesteps,features),name='encoder_inputs')\n",
    "#     encoder_lstm = LSTM(lstm_dim,return_state=True,name='encoder_lstm')\n",
    "#     encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "#     ###Input data is used by the encoder lstm and context vector is generated\n",
    "    \n",
    "#     states = [state_h,state_c]\n",
    "\n",
    "#     ###Decoder network defination\n",
    "#     decoder_inputs = Input(shape=(1, 1))\n",
    "#     decoder_lstm = LSTM(lstm_dim,return_state=True,return_sequences=True,name='decoder_lstm')\n",
    "#     decoder_dense = Dense(1,name='decoder_output')\n",
    "    \n",
    "#     all_outputs = []\n",
    "    \n",
    "#     attention= BahdanauAttention(lstm_dim, verbose=verbose)\n",
    "\n",
    "#     inputs = decoder_inputs\n",
    "    \n",
    "#     for _ in range(output_timesteps):\n",
    "        \n",
    "#         context_vector, attention_weights=attention(decoder_outputs, encoder_outputs)\n",
    "        \n",
    "#         lstm_outputs , state_h , state_c = decoder_lstm(inputs,initial_state=states)\n",
    "        \n",
    "#         outputs = decoder_dense(lstm_outputs)\n",
    "        \n",
    "#         states = [state_h,state_c]\n",
    "        \n",
    "#         all_outputs.append(outputs)\n",
    "        \n",
    "#         inputs = outputs\n",
    "        \n",
    "#     decoder_outputs = all_outputs\n",
    "    \n",
    "#     model = Model([encoder_inputs,decoder_inputs],decoder_outputs,name='encoder_decoder_model')\n",
    "    \n",
    "#     model.compile(optimizer='adam',loss=tf.keras.losses.Huber(),metrics=[\"mean_squared_error\"])\n",
    "    \n",
    "#     return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e188d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Model Hyperparameters****\n",
      "BATCH_SIZE :  128\n",
      "LSTM_DIM :  128\n",
      "INPUT_FEATURES :  10\n",
      "OUTPUT_FEATURES :  1\n",
      "TRAIN_STEPS :  168\n",
      "PREDICT_STEPS :  24\n"
     ]
    }
   ],
   "source": [
    "print('****Model Hyperparameters****')\n",
    "\n",
    "print('BATCH_SIZE : ',BATCH_SIZE)\n",
    "\n",
    "print('LSTM_DIM : ',LSTM_DIM)\n",
    "\n",
    "print('INPUT_FEATURES : ',INPUT_FEATURES)\n",
    "\n",
    "print('OUTPUT_FEATURES : ',OUTPUT_FEATURES)\n",
    "\n",
    "print('TRAIN_STEPS : ',TRAIN_STEPS)\n",
    "\n",
    "print('PREDICT_STEPS : ',PREDICT_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e6d5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enc_dec_att_model(BATCH_SIZE):\n",
    "    ## Enoder Model\n",
    "\n",
    "    encoder_input = Input(shape = (TRAIN_STEPS,INPUT_FEATURES),name='encoder_input')\n",
    "    \n",
    "    conv_layer = Conv1D(filters=filters,kernel_size=krnl_sz)\n",
    "    \n",
    "    pool_layer = tf.keras.layers.MaxPool1D(2)\n",
    "#    conv_flat_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())\n",
    "\n",
    "    encoder_lstm = GRU(LSTM_DIM , return_sequences=True,return_state=True,name='encoder_lstm')\n",
    "    \n",
    "    one_d_conv = conv_layer(encoder_input)\n",
    "    \n",
    "    pool = pool_layer(one_d_conv)\n",
    "#    conv_flat = conv_flat_layer(pool)\n",
    "\n",
    "    encoder_output , en_h  = encoder_lstm(pool)\n",
    "\n",
    "    encoder_states = [en_h]\n",
    "\n",
    "    attention_layer = BahdanauAttention(LSTM_DIM)\n",
    "\n",
    "    ## Decoder_Model\n",
    "\n",
    "    decoder_input = Input(shape = (1 , OUTPUT_FEATURES+LSTM_DIM) , name='decoder_input')\n",
    "    \n",
    "    decoder_lstm_2 = GRU(LSTM_DIM, return_sequences=True, return_state = True, name = 'decoder_lstm_2')\n",
    "\n",
    "    decoder_dense_1 = Dense(DECOD_DENSE,name='decoder_dense')\n",
    "    \n",
    "    decoder_output_layer = Dense(1,name='decoder_output')\n",
    "\n",
    "    all_outputs = []\n",
    "\n",
    "    ## Decoder input starting vector \n",
    "\n",
    "    inputs = np.zeros((BATCH_SIZE,1,OUTPUT_FEATURES),dtype=np.float32)\n",
    "\n",
    "    ##for attention\n",
    "\n",
    "    decoder_output = en_h\n",
    "\n",
    "    states = encoder_states\n",
    "    \n",
    "    for _ in range(PREDICT_STEPS):\n",
    "\n",
    "        context_vector , attention_weights = attention_layer(decoder_output,encoder_output)\n",
    "\n",
    "    #    print(\"Context Vector Shape : \",context_vector.shape)\n",
    "\n",
    "    #    print(\"Attention Weights : \",attention_weights.shape)\n",
    "\n",
    "    #    print(\"Decoder Output Before Concat : \",decoder_output.shape)\n",
    "\n",
    "#        context_vector = tf.expand_dims(context_vector,1)\n",
    "\n",
    "    #    context_vector = tf.cast(context_vector,tf.float64)\n",
    "\n",
    "    #    print(\"Reshaped Context Vector : \",context_vector.shape)\n",
    "\n",
    "    #    print(\"Input Shape : \",inputs.shape)\n",
    "\n",
    "#        inputs = tf.concat([context_vector,inputs],axis=-1)\n",
    "\n",
    "    #    print(\"New Input Shape: \",inputs.shape)\n",
    "\n",
    "#        x = decoder_lstm_1(decoder_input,initial_state=states)\n",
    "        \n",
    "        decoder_outputs, state_h  = decoder_lstm_2(decoder_input,initial_state=states)\n",
    "\n",
    "        output = decoder_output_layer(decoder_outputs)\n",
    "        \n",
    "    #    print(\"Decoder Output : \",output.shape)\n",
    "\n",
    "    #    output = tf.expand_dims(output,1)\n",
    "\n",
    "        all_outputs.append(output)\n",
    "\n",
    "        inputs = output\n",
    "\n",
    "        states = [state_h]\n",
    "        \n",
    "    all_out = Lambda(lambda x: tf.keras.backend.concatenate(x, axis=1))(all_outputs)\n",
    "    \n",
    "    ##Flatten layer\n",
    "    \n",
    "    flat_layer = tf.keras.layers.Flatten()\n",
    "    \n",
    "    all_out = flat_layer(all_out)\n",
    "        \n",
    "    ###Defining Fullyy connected layer \n",
    "    \n",
    "    fc_layer = Dense(128,name='FC_LAYER'\n",
    "#                     ,kernel_regularizer=tf.keras.regularizers.L2(0.01)\n",
    "                    )\n",
    "    \n",
    "    output_layer = Dense(24,name='output_layer')\n",
    "\n",
    "    fc_layer_1 = fc_layer(all_out)\n",
    "    \n",
    "    final_output = output_layer(fc_layer_1)\n",
    "    \n",
    "    model = Model([encoder_input,decoder_input], final_output, name='model_encoder_decoder')\n",
    "\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.Huber(), metrics=['mean_squared_error'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9a70315",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_Model = create_enc_dec_att_model(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bff45d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_encoder_decoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 168, 10)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 167, 16)      336         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 83, 16)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 1, 129)]     0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (GRU)             [(None, 83, 128),    56064       ['max_pooling1d[0][0]']          \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm_2 (GRU)           [(None, 1, 128),     99456       ['decoder_input[0][0]',          \n",
      "                                 (None, 128)]                     'encoder_lstm[0][1]',           \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[0][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[1][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[2][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[3][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[4][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[5][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[6][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[7][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[8][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[9][1]',         \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[10][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[11][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[12][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[13][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[14][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[15][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[16][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[17][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[18][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[19][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[20][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[21][1]',        \n",
      "                                                                  'decoder_input[0][0]',          \n",
      "                                                                  'decoder_lstm_2[22][1]']        \n",
      "                                                                                                  \n",
      " decoder_output (Dense)         (None, 1, 1)         129         ['decoder_lstm_2[0][0]',         \n",
      "                                                                  'decoder_lstm_2[1][0]',         \n",
      "                                                                  'decoder_lstm_2[2][0]',         \n",
      "                                                                  'decoder_lstm_2[3][0]',         \n",
      "                                                                  'decoder_lstm_2[4][0]',         \n",
      "                                                                  'decoder_lstm_2[5][0]',         \n",
      "                                                                  'decoder_lstm_2[6][0]',         \n",
      "                                                                  'decoder_lstm_2[7][0]',         \n",
      "                                                                  'decoder_lstm_2[8][0]',         \n",
      "                                                                  'decoder_lstm_2[9][0]',         \n",
      "                                                                  'decoder_lstm_2[10][0]',        \n",
      "                                                                  'decoder_lstm_2[11][0]',        \n",
      "                                                                  'decoder_lstm_2[12][0]',        \n",
      "                                                                  'decoder_lstm_2[13][0]',        \n",
      "                                                                  'decoder_lstm_2[14][0]',        \n",
      "                                                                  'decoder_lstm_2[15][0]',        \n",
      "                                                                  'decoder_lstm_2[16][0]',        \n",
      "                                                                  'decoder_lstm_2[17][0]',        \n",
      "                                                                  'decoder_lstm_2[18][0]',        \n",
      "                                                                  'decoder_lstm_2[19][0]',        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'decoder_lstm_2[20][0]',        \n",
      "                                                                  'decoder_lstm_2[21][0]',        \n",
      "                                                                  'decoder_lstm_2[22][0]',        \n",
      "                                                                  'decoder_lstm_2[23][0]']        \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 24, 1)        0           ['decoder_output[0][0]',         \n",
      "                                                                  'decoder_output[1][0]',         \n",
      "                                                                  'decoder_output[2][0]',         \n",
      "                                                                  'decoder_output[3][0]',         \n",
      "                                                                  'decoder_output[4][0]',         \n",
      "                                                                  'decoder_output[5][0]',         \n",
      "                                                                  'decoder_output[6][0]',         \n",
      "                                                                  'decoder_output[7][0]',         \n",
      "                                                                  'decoder_output[8][0]',         \n",
      "                                                                  'decoder_output[9][0]',         \n",
      "                                                                  'decoder_output[10][0]',        \n",
      "                                                                  'decoder_output[11][0]',        \n",
      "                                                                  'decoder_output[12][0]',        \n",
      "                                                                  'decoder_output[13][0]',        \n",
      "                                                                  'decoder_output[14][0]',        \n",
      "                                                                  'decoder_output[15][0]',        \n",
      "                                                                  'decoder_output[16][0]',        \n",
      "                                                                  'decoder_output[17][0]',        \n",
      "                                                                  'decoder_output[18][0]',        \n",
      "                                                                  'decoder_output[19][0]',        \n",
      "                                                                  'decoder_output[20][0]',        \n",
      "                                                                  'decoder_output[21][0]',        \n",
      "                                                                  'decoder_output[22][0]',        \n",
      "                                                                  'decoder_output[23][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 24)           0           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " FC_LAYER (Dense)               (None, 128)          3200        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 24)           3096        ['FC_LAYER[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 162,281\n",
      "Trainable params: 162,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "My_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b295552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4096 - mean_squared_error: 0.9277\n",
      "Epoch 1: val_loss improved from inf to 0.30302, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 60s 1s/step - loss: 0.4088 - mean_squared_error: 0.9257 - val_loss: 0.3030 - val_mean_squared_error: 0.6705\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2644 - mean_squared_error: 0.5760\n",
      "Epoch 2: val_loss improved from 0.30302 to 0.19729, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.2644 - mean_squared_error: 0.5760 - val_loss: 0.1973 - val_mean_squared_error: 0.4157\n",
      "Epoch 3/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1592 - mean_squared_error: 0.3307\n",
      "Epoch 3: val_loss improved from 0.19729 to 0.15346, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.1590 - mean_squared_error: 0.3303 - val_loss: 0.1535 - val_mean_squared_error: 0.3147\n",
      "Epoch 4/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1318 - mean_squared_error: 0.2710\n",
      "Epoch 4: val_loss improved from 0.15346 to 0.14406, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.1319 - mean_squared_error: 0.2712 - val_loss: 0.1441 - val_mean_squared_error: 0.2958\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1117 - mean_squared_error: 0.2297\n",
      "Epoch 5: val_loss improved from 0.14406 to 0.13191, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.1117 - mean_squared_error: 0.2297 - val_loss: 0.1319 - val_mean_squared_error: 0.2690\n",
      "Epoch 6/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0994 - mean_squared_error: 0.2028\n",
      "Epoch 6: val_loss improved from 0.13191 to 0.12513, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0994 - mean_squared_error: 0.2030 - val_loss: 0.1251 - val_mean_squared_error: 0.2552\n",
      "Epoch 7/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0950 - mean_squared_error: 0.1940\n",
      "Epoch 7: val_loss improved from 0.12513 to 0.11601, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.0949 - mean_squared_error: 0.1936 - val_loss: 0.1160 - val_mean_squared_error: 0.2365\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0909 - mean_squared_error: 0.1861\n",
      "Epoch 8: val_loss improved from 0.11601 to 0.11516, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0909 - mean_squared_error: 0.1861 - val_loss: 0.1152 - val_mean_squared_error: 0.2343\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0919 - mean_squared_error: 0.1879\n",
      "Epoch 9: val_loss did not improve from 0.11516\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0919 - mean_squared_error: 0.1879 - val_loss: 0.1235 - val_mean_squared_error: 0.2529\n",
      "Epoch 10/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0892 - mean_squared_error: 0.1823\n",
      "Epoch 10: val_loss did not improve from 0.11516\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0892 - mean_squared_error: 0.1823 - val_loss: 0.1241 - val_mean_squared_error: 0.2542\n",
      "Epoch 11/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0897 - mean_squared_error: 0.1837\n",
      "Epoch 11: val_loss did not improve from 0.11516\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0895 - mean_squared_error: 0.1834 - val_loss: 0.1181 - val_mean_squared_error: 0.2417\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0867 - mean_squared_error: 0.1771\n",
      "Epoch 12: val_loss did not improve from 0.11516\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0867 - mean_squared_error: 0.1771 - val_loss: 0.1166 - val_mean_squared_error: 0.2378\n",
      "Epoch 13/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0848 - mean_squared_error: 0.1745\n",
      "Epoch 13: val_loss did not improve from 0.11516\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0847 - mean_squared_error: 0.1743 - val_loss: 0.1307 - val_mean_squared_error: 0.2678\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0895 - mean_squared_error: 0.1830\n",
      "Epoch 14: val_loss improved from 0.11516 to 0.11145, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0895 - mean_squared_error: 0.1830 - val_loss: 0.1115 - val_mean_squared_error: 0.2267\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0827 - mean_squared_error: 0.1688\n",
      "Epoch 15: val_loss did not improve from 0.11145\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0827 - mean_squared_error: 0.1688 - val_loss: 0.1161 - val_mean_squared_error: 0.2372\n",
      "Epoch 16/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0815 - mean_squared_error: 0.1674\n",
      "Epoch 16: val_loss did not improve from 0.11145\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0819 - mean_squared_error: 0.1682 - val_loss: 0.1205 - val_mean_squared_error: 0.2469\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.1741\n",
      "Epoch 17: val_loss did not improve from 0.11145\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0852 - mean_squared_error: 0.1741 - val_loss: 0.1206 - val_mean_squared_error: 0.2452\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0842 - mean_squared_error: 0.1725\n",
      "Epoch 18: val_loss improved from 0.11145 to 0.11009, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.0842 - mean_squared_error: 0.1725 - val_loss: 0.1101 - val_mean_squared_error: 0.2246\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.1724\n",
      "Epoch 19: val_loss did not improve from 0.11009\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0838 - mean_squared_error: 0.1724 - val_loss: 0.1227 - val_mean_squared_error: 0.2505\n",
      "Epoch 20/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0844 - mean_squared_error: 0.1718\n",
      "Epoch 20: val_loss improved from 0.11009 to 0.10929, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.0845 - mean_squared_error: 0.1721 - val_loss: 0.1093 - val_mean_squared_error: 0.2213\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0802 - mean_squared_error: 0.1641\n",
      "Epoch 21: val_loss did not improve from 0.10929\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0802 - mean_squared_error: 0.1641 - val_loss: 0.1190 - val_mean_squared_error: 0.2440\n",
      "Epoch 22/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0753 - mean_squared_error: 0.1539\n",
      "Epoch 22: val_loss improved from 0.10929 to 0.10639, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0752 - mean_squared_error: 0.1537 - val_loss: 0.1064 - val_mean_squared_error: 0.2164\n",
      "Epoch 23/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0751 - mean_squared_error: 0.1536\n",
      "Epoch 23: val_loss did not improve from 0.10639\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0750 - mean_squared_error: 0.1534 - val_loss: 0.1094 - val_mean_squared_error: 0.2217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0720 - mean_squared_error: 0.1473\n",
      "Epoch 24: val_loss improved from 0.10639 to 0.10223, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.0720 - mean_squared_error: 0.1473 - val_loss: 0.1022 - val_mean_squared_error: 0.2071\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0689 - mean_squared_error: 0.1407\n",
      "Epoch 25: val_loss did not improve from 0.10223\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0689 - mean_squared_error: 0.1407 - val_loss: 0.1064 - val_mean_squared_error: 0.2170\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0712 - mean_squared_error: 0.1450\n",
      "Epoch 26: val_loss improved from 0.10223 to 0.09430, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.0712 - mean_squared_error: 0.1450 - val_loss: 0.0943 - val_mean_squared_error: 0.1908\n",
      "Epoch 27/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0681 - mean_squared_error: 0.1387\n",
      "Epoch 27: val_loss did not improve from 0.09430\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0681 - mean_squared_error: 0.1387 - val_loss: 0.0958 - val_mean_squared_error: 0.1938\n",
      "Epoch 28/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0675 - mean_squared_error: 0.1375\n",
      "Epoch 28: val_loss improved from 0.09430 to 0.08581, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0675 - mean_squared_error: 0.1374 - val_loss: 0.0858 - val_mean_squared_error: 0.1742\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0639 - mean_squared_error: 0.1303\n",
      "Epoch 29: val_loss did not improve from 0.08581\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.0639 - mean_squared_error: 0.1303 - val_loss: 0.0882 - val_mean_squared_error: 0.1787\n",
      "Epoch 30/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0660 - mean_squared_error: 0.1347\n",
      "Epoch 30: val_loss did not improve from 0.08581\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0659 - mean_squared_error: 0.1345 - val_loss: 0.0951 - val_mean_squared_error: 0.1930\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0607 - mean_squared_error: 0.1237\n",
      "Epoch 31: val_loss improved from 0.08581 to 0.07972, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.0607 - mean_squared_error: 0.1237 - val_loss: 0.0797 - val_mean_squared_error: 0.1608\n",
      "Epoch 32/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0580 - mean_squared_error: 0.1185\n",
      "Epoch 32: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0582 - mean_squared_error: 0.1190 - val_loss: 0.0917 - val_mean_squared_error: 0.1874\n",
      "Epoch 33/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.1696\n",
      "Epoch 33: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0831 - mean_squared_error: 0.1695 - val_loss: 0.1123 - val_mean_squared_error: 0.2282\n",
      "Epoch 34/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0731 - mean_squared_error: 0.1491\n",
      "Epoch 34: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0730 - mean_squared_error: 0.1489 - val_loss: 0.1066 - val_mean_squared_error: 0.2175\n",
      "Epoch 35/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0672 - mean_squared_error: 0.1370\n",
      "Epoch 35: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0671 - mean_squared_error: 0.1368 - val_loss: 0.0986 - val_mean_squared_error: 0.2009\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0639 - mean_squared_error: 0.1304\n",
      "Epoch 36: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0639 - mean_squared_error: 0.1304 - val_loss: 0.1054 - val_mean_squared_error: 0.2147\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0631 - mean_squared_error: 0.1286\n",
      "Epoch 37: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.0631 - mean_squared_error: 0.1286 - val_loss: 0.0814 - val_mean_squared_error: 0.1650\n",
      "Epoch 38/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0665 - mean_squared_error: 0.1355\n",
      "Epoch 38: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0664 - mean_squared_error: 0.1353 - val_loss: 0.1051 - val_mean_squared_error: 0.2143\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.1224\n",
      "Epoch 39: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.0601 - mean_squared_error: 0.1224 - val_loss: 0.0937 - val_mean_squared_error: 0.1905\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.1242\n",
      "Epoch 40: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.0611 - mean_squared_error: 0.1242 - val_loss: 0.0836 - val_mean_squared_error: 0.1691\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0572 - mean_squared_error: 0.1166\n",
      "Epoch 41: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.0572 - mean_squared_error: 0.1166 - val_loss: 0.0950 - val_mean_squared_error: 0.1921\n",
      "Epoch 42/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.1136\n",
      "Epoch 42: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.0558 - mean_squared_error: 0.1137 - val_loss: 0.0829 - val_mean_squared_error: 0.1670\n",
      "Epoch 43/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0578 - mean_squared_error: 0.1177\n",
      "Epoch 43: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0576 - mean_squared_error: 0.1174 - val_loss: 0.0947 - val_mean_squared_error: 0.1921\n",
      "Epoch 44/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0538 - mean_squared_error: 0.1097\n",
      "Epoch 44: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0538 - mean_squared_error: 0.1097 - val_loss: 0.0856 - val_mean_squared_error: 0.1727\n",
      "Epoch 45/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0532 - mean_squared_error: 0.1085\n",
      "Epoch 45: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0532 - mean_squared_error: 0.1084 - val_loss: 0.0812 - val_mean_squared_error: 0.1638\n",
      "Epoch 46/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0524 - mean_squared_error: 0.1068\n",
      "Epoch 46: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0523 - mean_squared_error: 0.1067 - val_loss: 0.0849 - val_mean_squared_error: 0.1709\n",
      "Epoch 47/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0525 - mean_squared_error: 0.1069\n",
      "Epoch 47: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0524 - mean_squared_error: 0.1067 - val_loss: 0.0914 - val_mean_squared_error: 0.1848\n",
      "Epoch 48/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0512 - mean_squared_error: 0.1043\n",
      "Epoch 48: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0511 - mean_squared_error: 0.1041 - val_loss: 0.0807 - val_mean_squared_error: 0.1628\n",
      "Epoch 49/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0503 - mean_squared_error: 0.1027\n",
      "Epoch 49: val_loss did not improve from 0.07972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0502 - mean_squared_error: 0.1025 - val_loss: 0.0828 - val_mean_squared_error: 0.1673\n",
      "Epoch 50/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.1016\n",
      "Epoch 50: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0498 - mean_squared_error: 0.1015 - val_loss: 0.0908 - val_mean_squared_error: 0.1834\n",
      "Epoch 51/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0501 - mean_squared_error: 0.1022\n",
      "Epoch 51: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0501 - mean_squared_error: 0.1021 - val_loss: 0.0838 - val_mean_squared_error: 0.1687\n",
      "Epoch 52/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.1030\n",
      "Epoch 52: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0504 - mean_squared_error: 0.1029 - val_loss: 0.0859 - val_mean_squared_error: 0.1737\n",
      "Epoch 53/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0473 - mean_squared_error: 0.0966\n",
      "Epoch 53: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0473 - mean_squared_error: 0.0967 - val_loss: 0.0857 - val_mean_squared_error: 0.1727\n",
      "Epoch 54/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1037\n",
      "Epoch 54: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0508 - mean_squared_error: 0.1038 - val_loss: 0.0881 - val_mean_squared_error: 0.1787\n",
      "Epoch 55/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0488 - mean_squared_error: 0.0994\n",
      "Epoch 55: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0488 - mean_squared_error: 0.0994 - val_loss: 0.0951 - val_mean_squared_error: 0.1920\n",
      "Epoch 56/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0487 - mean_squared_error: 0.0994\n",
      "Epoch 56: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0487 - mean_squared_error: 0.0995 - val_loss: 0.0830 - val_mean_squared_error: 0.1675\n",
      "Epoch 57/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0484 - mean_squared_error: 0.0988\n",
      "Epoch 57: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0483 - mean_squared_error: 0.0987 - val_loss: 0.0865 - val_mean_squared_error: 0.1741\n",
      "Epoch 58/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0468 - mean_squared_error: 0.0956\n",
      "Epoch 58: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0469 - mean_squared_error: 0.0959 - val_loss: 0.0815 - val_mean_squared_error: 0.1640\n",
      "Epoch 59/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0480 - mean_squared_error: 0.0981\n",
      "Epoch 59: val_loss did not improve from 0.07972\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0480 - mean_squared_error: 0.0980 - val_loss: 0.0927 - val_mean_squared_error: 0.1871\n",
      "Epoch 60/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0972\n",
      "Epoch 60: val_loss improved from 0.07972 to 0.07760, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0476 - mean_squared_error: 0.0971 - val_loss: 0.0776 - val_mean_squared_error: 0.1564\n",
      "Epoch 61/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0556 - mean_squared_error: 0.1138\n",
      "Epoch 61: val_loss did not improve from 0.07760\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0555 - mean_squared_error: 0.1137 - val_loss: 0.1044 - val_mean_squared_error: 0.2129\n",
      "Epoch 62/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.1131\n",
      "Epoch 62: val_loss did not improve from 0.07760\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0555 - mean_squared_error: 0.1133 - val_loss: 0.1118 - val_mean_squared_error: 0.2278\n",
      "Epoch 63/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0646 - mean_squared_error: 0.1323\n",
      "Epoch 63: val_loss did not improve from 0.07760\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0646 - mean_squared_error: 0.1323 - val_loss: 0.0777 - val_mean_squared_error: 0.1565\n",
      "Epoch 64/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0558 - mean_squared_error: 0.1140\n",
      "Epoch 64: val_loss did not improve from 0.07760\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0557 - mean_squared_error: 0.1138 - val_loss: 0.0987 - val_mean_squared_error: 0.1994\n",
      "Epoch 65/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0483 - mean_squared_error: 0.0986\n",
      "Epoch 65: val_loss improved from 0.07760 to 0.07426, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.0483 - mean_squared_error: 0.0985 - val_loss: 0.0743 - val_mean_squared_error: 0.1495\n",
      "Epoch 66/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0905\n",
      "Epoch 66: val_loss improved from 0.07426 to 0.07415, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0443 - mean_squared_error: 0.0905 - val_loss: 0.0741 - val_mean_squared_error: 0.1490\n",
      "Epoch 67/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0929\n",
      "Epoch 67: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0455 - mean_squared_error: 0.0930 - val_loss: 0.0917 - val_mean_squared_error: 0.1852\n",
      "Epoch 68/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0463 - mean_squared_error: 0.0944\n",
      "Epoch 68: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0463 - mean_squared_error: 0.0944 - val_loss: 0.0855 - val_mean_squared_error: 0.1723\n",
      "Epoch 69/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0895\n",
      "Epoch 69: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0440 - mean_squared_error: 0.0899 - val_loss: 0.0805 - val_mean_squared_error: 0.1620\n",
      "Epoch 70/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0465 - mean_squared_error: 0.0948\n",
      "Epoch 70: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0465 - mean_squared_error: 0.0948 - val_loss: 0.0753 - val_mean_squared_error: 0.1517\n",
      "Epoch 71/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.1039\n",
      "Epoch 71: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0508 - mean_squared_error: 0.1039 - val_loss: 0.0858 - val_mean_squared_error: 0.1727\n",
      "Epoch 72/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.0964\n",
      "Epoch 72: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0472 - mean_squared_error: 0.0963 - val_loss: 0.0881 - val_mean_squared_error: 0.1782\n",
      "Epoch 73/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0460 - mean_squared_error: 0.0939\n",
      "Epoch 73: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0460 - mean_squared_error: 0.0939 - val_loss: 0.0771 - val_mean_squared_error: 0.1557\n",
      "Epoch 74/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0941\n",
      "Epoch 74: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0461 - mean_squared_error: 0.0940 - val_loss: 0.0840 - val_mean_squared_error: 0.1692\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0424 - mean_squared_error: 0.0867\n",
      "Epoch 75: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0424 - mean_squared_error: 0.0866 - val_loss: 0.0767 - val_mean_squared_error: 0.1543\n",
      "Epoch 76/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0892\n",
      "Epoch 76: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0437 - mean_squared_error: 0.0891 - val_loss: 0.0838 - val_mean_squared_error: 0.1691\n",
      "Epoch 77/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0865\n",
      "Epoch 77: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0423 - mean_squared_error: 0.0864 - val_loss: 0.0947 - val_mean_squared_error: 0.1912\n",
      "Epoch 78/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.0842\n",
      "Epoch 78: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.0412 - mean_squared_error: 0.0842 - val_loss: 0.0761 - val_mean_squared_error: 0.1534\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0905\n",
      "Epoch 79: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0443 - mean_squared_error: 0.0905 - val_loss: 0.0748 - val_mean_squared_error: 0.1511\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0944\n",
      "Epoch 80: val_loss did not improve from 0.07415\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0462 - mean_squared_error: 0.0944 - val_loss: 0.1125 - val_mean_squared_error: 0.2276\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0506 - mean_squared_error: 0.1032\n",
      "Epoch 81: val_loss improved from 0.07415 to 0.07406, saving model to 1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0506 - mean_squared_error: 0.1032 - val_loss: 0.0741 - val_mean_squared_error: 0.1489\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0925\n",
      "Epoch 82: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0454 - mean_squared_error: 0.0925 - val_loss: 0.0774 - val_mean_squared_error: 0.1556\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0825\n",
      "Epoch 83: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0403 - mean_squared_error: 0.0825 - val_loss: 0.0792 - val_mean_squared_error: 0.1594\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0799\n",
      "Epoch 84: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0391 - mean_squared_error: 0.0799 - val_loss: 0.0794 - val_mean_squared_error: 0.1600\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0801\n",
      "Epoch 85: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0391 - mean_squared_error: 0.0801 - val_loss: 0.0825 - val_mean_squared_error: 0.1660\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0788\n",
      "Epoch 86: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0385 - mean_squared_error: 0.0788 - val_loss: 0.0827 - val_mean_squared_error: 0.1667\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0766\n",
      "Epoch 87: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0374 - mean_squared_error: 0.0766 - val_loss: 0.0898 - val_mean_squared_error: 0.1810\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0379 - mean_squared_error: 0.0777\n",
      "Epoch 88: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0379 - mean_squared_error: 0.0777 - val_loss: 0.0759 - val_mean_squared_error: 0.1528\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0782\n",
      "Epoch 89: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0382 - mean_squared_error: 0.0782 - val_loss: 0.0805 - val_mean_squared_error: 0.1622\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0809\n",
      "Epoch 90: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0396 - mean_squared_error: 0.0809 - val_loss: 0.0850 - val_mean_squared_error: 0.1714\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0379 - mean_squared_error: 0.0776\n",
      "Epoch 91: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0379 - mean_squared_error: 0.0776 - val_loss: 0.0750 - val_mean_squared_error: 0.1508\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0871\n",
      "Epoch 92: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.0426 - mean_squared_error: 0.0871 - val_loss: 0.0850 - val_mean_squared_error: 0.1713\n",
      "Epoch 93/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0803\n",
      "Epoch 93: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0392 - mean_squared_error: 0.0802 - val_loss: 0.0896 - val_mean_squared_error: 0.1806\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0772\n",
      "Epoch 94: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0377 - mean_squared_error: 0.0772 - val_loss: 0.0805 - val_mean_squared_error: 0.1621\n",
      "Epoch 95/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0737\n",
      "Epoch 95: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0360 - mean_squared_error: 0.0736 - val_loss: 0.0792 - val_mean_squared_error: 0.1592\n",
      "Epoch 96/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0358 - mean_squared_error: 0.0734\n",
      "Epoch 96: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0358 - mean_squared_error: 0.0733 - val_loss: 0.0755 - val_mean_squared_error: 0.1519\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0697\n",
      "Epoch 97: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0340 - mean_squared_error: 0.0697 - val_loss: 0.0809 - val_mean_squared_error: 0.1628\n",
      "Epoch 98/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0729\n",
      "Epoch 98: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0356 - mean_squared_error: 0.0728 - val_loss: 0.0861 - val_mean_squared_error: 0.1736\n",
      "Epoch 99/100\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0364 - mean_squared_error: 0.0744\n",
      "Epoch 99: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0365 - mean_squared_error: 0.0745 - val_loss: 0.0815 - val_mean_squared_error: 0.1639\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0750\n",
      "Epoch 100: val_loss did not improve from 0.07406\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0366 - mean_squared_error: 0.0750 - val_loss: 0.0767 - val_mean_squared_error: 0.1544\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.1,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.5)\n",
    "\n",
    "model_chk = tf.keras.callbacks.ModelCheckpoint(\n",
    "            '1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5',monitor=\"val_loss\",mode='min',verbose=1,save_best_only=True\n",
    ")\n",
    "\n",
    "history = My_Model.fit(x=[tra_data_sli,tra_decod],y=tra_lab, epochs=MAX_EPOCH, batch_size=BATCH_SIZE,validation_data=([val_data_sli,val_decod], val_lab), verbose=1,callbacks=[model_chk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f9d8c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 10s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = My_Model.predict(x=[tes_data_sli,tes_decod])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38347b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 24)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "135c7ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 24)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a2fa4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3576, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(predict.flatten().reshape(-1,1),10,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e09a366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = test_scaler.inverse_transform(np.repeat(predict.flatten().reshape(-1,1),10,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13b02833",
   "metadata": {},
   "outputs": [],
   "source": [
    "grou_tru = test_scaler.inverse_transform(np.repeat(tes_lab.flatten().reshape(-1,1),10,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d42be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8eb2db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error is  282324.99293149984\n",
      "The mean abolsute error is  412.53251876660374\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean squared error is \", mean_squared_error(grou_tru[:,0],prediction[:,0]))\n",
    "print(\"The mean abolsute error is \", mean_absolute_error(grou_tru[:,0],prediction[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba376ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x238d2a5b460>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['val_loss', 'loss'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cafb9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 11s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "model_seq_to_seq_with_atten = keras.models.load_model('1 Weekly Seq2Seq GRU FC Layer Implementation Old University Data Using Std Scaler.h5') \n",
    "predict_wout_attention = model_seq_to_seq_with_atten.predict(x=[tes_data_sli,tes_decod])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e37fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grou_tru = test_scaler.inverse_transform(np.repeat(tes_lab.flatten().reshape(-1,1),10,axis=1))\n",
    "prediction_without_attention = test_scaler.inverse_transform(np.repeat(predict_wout_attention.flatten().reshape(-1,1),10,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6742f29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287450.0024865983\n",
      "415.8421527085955\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(grou_tru[:,0],prediction_without_attention[:,0]))\n",
    "print(mean_absolute_error(grou_tru[:,0],prediction_without_attention[:,0]))\n",
    "#print((r2_score(grou_tru[:,0],prediction_without_attention[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86252831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load(KW)</th>\n",
       "      <th>Temp (°C)</th>\n",
       "      <th>Dew Point Temp (°C)</th>\n",
       "      <th>Rel Hum (%)</th>\n",
       "      <th>Wind Dir (10s deg)</th>\n",
       "      <th>Wind Spd (km/h)</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Stn Press (kPa)</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-28 00:00:00</th>\n",
       "      <td>10152.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>99.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28 01:00:00</th>\n",
       "      <td>10092.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>99.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28 02:00:00</th>\n",
       "      <td>9960.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>99.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28 03:00:00</th>\n",
       "      <td>10008.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>96.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>99.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28 04:00:00</th>\n",
       "      <td>10296.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>99.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 19:00:00</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>99.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 20:00:00</th>\n",
       "      <td>10332.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>99.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 21:00:00</th>\n",
       "      <td>9984.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 22:00:00</th>\n",
       "      <td>9744.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 23:00:00</th>\n",
       "      <td>9660.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3744 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Load(KW)     Temp (°C)  Dew Point Temp (°C)  \\\n",
       "datetime                                                            \n",
       "2019-10-28 00:00:00       10152.0        3.6                  2.5   \n",
       "2019-10-28 01:00:00       10092.0        3.7                  3.0   \n",
       "2019-10-28 02:00:00        9960.0        4.0                  3.5   \n",
       "2019-10-28 03:00:00       10008.0        3.4                  2.8   \n",
       "2019-10-28 04:00:00       10296.0        2.8                  2.2   \n",
       "...                           ...        ...                  ...   \n",
       "2020-03-31 19:00:00       10500.0        0.6                  0.4   \n",
       "2020-03-31 20:00:00       10332.0        1.6                  1.4   \n",
       "2020-03-31 21:00:00        9984.0        2.3                  2.1   \n",
       "2020-03-31 22:00:00        9744.0        2.6                  2.5   \n",
       "2020-03-31 23:00:00        9660.0        2.2                  2.1   \n",
       "\n",
       "                     Rel Hum (%)  Wind Dir (10s deg)  Wind Spd (km/h)  \\\n",
       "datetime                                                                \n",
       "2019-10-28 00:00:00         92.0                36.0             23.0   \n",
       "2019-10-28 01:00:00         95.0                36.0             18.0   \n",
       "2019-10-28 02:00:00         96.0                35.0             20.0   \n",
       "2019-10-28 03:00:00         96.0                36.0             30.0   \n",
       "2019-10-28 04:00:00         96.0                36.0             29.0   \n",
       "...                          ...                 ...              ...   \n",
       "2020-03-31 19:00:00         99.0                 9.0             10.0   \n",
       "2020-03-31 20:00:00         99.0                11.0             14.0   \n",
       "2020-03-31 21:00:00         99.0                14.0             17.0   \n",
       "2020-03-31 22:00:00         99.0                15.0             17.0   \n",
       "2020-03-31 23:00:00         99.0                14.0             18.0   \n",
       "\n",
       "                     Visibility (km)  Stn Press (kPa)  is_weekday  month  \n",
       "datetime                                                                  \n",
       "2019-10-28 00:00:00             24.1            99.83         1.0   10.0  \n",
       "2019-10-28 01:00:00             16.1            99.85         1.0   10.0  \n",
       "2019-10-28 02:00:00             16.1            99.88         1.0   10.0  \n",
       "2019-10-28 03:00:00              8.1            99.88         1.0   10.0  \n",
       "2019-10-28 04:00:00              8.1            99.92         1.0   10.0  \n",
       "...                              ...              ...         ...    ...  \n",
       "2020-03-31 19:00:00              0.6            99.93         1.0    3.0  \n",
       "2020-03-31 20:00:00              0.2            99.97         1.0    3.0  \n",
       "2020-03-31 21:00:00              0.2           100.00         1.0    3.0  \n",
       "2020-03-31 22:00:00              0.2           100.03         1.0    3.0  \n",
       "2020-03-31 23:00:00              0.2           100.05         1.0    3.0  \n",
       "\n",
       "[3744 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bece6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a1032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34698f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0dc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8cc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7982e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb0fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358618c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf30e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf37b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d7f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97385cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954ceb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26134c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228e8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6562dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60987e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93a09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f63d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d2635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecd32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970f5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2568d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f77d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839d31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222dec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c5509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576c70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a5830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee6a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf19db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_data_sli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_data_sli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b21b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bef3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2dc972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdbf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aad762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67a4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59ac38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b31d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a74901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a2feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89383ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720123a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813b8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1accb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42006b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd8868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db28aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6864c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258a55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb49cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
